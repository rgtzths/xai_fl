{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import random\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "rus = RandomUnderSampler(random_state=seed, sampling_strategy=0.05)\n",
    "\n",
    "input_path = \"train\"\n",
    "input = pathlib.Path(input_path)\n",
    "\n",
    "distances_file = input/\"distances.tsv\"\n",
    "rl_sites_file = input/\"rl-sites.tsv\"\n",
    "\n",
    "dataset_path = \"./preprocessed/train\"\n",
    "\n",
    "dataset =  pathlib.Path(dataset_path)\n",
    "\n",
    "identifiers = [\"site_id\", \"mlid\", \"datetime\"]\n",
    "\n",
    "labels = [\"rlf\", \"1-day-predict\", \"5-day-predict\"]\n",
    "\n",
    "distances_df = pd.read_csv(distances_file, sep=\"\\t\", index_col=0)\n",
    "rl_sites_df = pd.read_csv(rl_sites_file, sep=\"\\t\", index_col=0)\n",
    "\n",
    "rl_stations = rl_sites_df[\"site_id\"].unique()\n",
    "\n",
    "distances_df = distances_df.loc[rl_stations, rl_stations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate for N workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating subset with 2 workers\n",
      "Combining subset's files\n",
      "Undersampling\n",
      "Creating subset with 4 workers\n",
      "Combining subset's files\n",
      "Undersampling\n",
      "Creating subset with 8 workers\n",
      "Combining subset's files\n",
      "Undersampling\n"
     ]
    }
   ],
   "source": [
    "for n_divisions in [2, 4, 8]:\n",
    "    print(f\"Creating subset with {n_divisions} workers\")\n",
    "    output_path = f\"./divided/train/{n_divisions}_workers\"\n",
    "\n",
    "    output = pathlib.Path(output_path)\n",
    "    output.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    #Define station grouping based on HC\n",
    "\n",
    "    clustering = AgglomerativeClustering(n_clusters=8, metric='precomputed', linkage='complete').fit(distances_df.values)\n",
    "\n",
    "    cluster_labels = clustering.labels_\n",
    "\n",
    "    clusters = {}\n",
    "\n",
    "    for idx, value in enumerate(cluster_labels):\n",
    "        if value in clusters:\n",
    "            clusters[value].append(rl_stations[idx])\n",
    "        else:\n",
    "            clusters[value] = [rl_stations[idx]]\n",
    "\n",
    "    print(f\"Combining subset's files\")\n",
    "    for idx in range(n_divisions):\n",
    "        (output/\"raw\").mkdir(parents=True, exist_ok=True)\n",
    "        x_subset_file = open(output/f\"raw/x_train_subset_{idx+1}.csv\", \"wb\")\n",
    "        y_subset_file = open(output/f\"raw/y_train_subset_{idx+1}.csv\", \"wb\")\n",
    "\n",
    "        for rl_sation in clusters[idx]:\n",
    "            if (dataset/rl_sation).exists():\n",
    "                for file in [x for x in (dataset/rl_sation).iterdir() if x.is_file()]:\n",
    "                    df = pd.read_csv(file)\n",
    "\n",
    "                    time_sentitive_features = [feature for feature in df.columns if feature not in labels and feature not in identifiers]\n",
    "                    np.savetxt(x_subset_file, df[time_sentitive_features].values, delimiter=\",\", fmt=\"%5.2f\")\n",
    "                    np.savetxt(y_subset_file, df[[\"5-day-predict\"]].values, delimiter=\",\", fmt=\"%d\")\n",
    "\n",
    "        x_subset_file.close()\n",
    "        y_subset_file.close()\n",
    "\n",
    "    print(\"Undersampling\")\n",
    "    for idx in range(n_divisions):\n",
    "        (output/\"under\").mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        X_train = np.loadtxt(output/f\"raw/x_train_subset_{idx+1}.csv\", delimiter=\",\")\n",
    "        y_train = np.loadtxt(output/f\"raw/y_train_subset_{idx+1}.csv\", delimiter=\",\")\n",
    "\n",
    "        final_X_array, final_y_array = rus.fit_resample(X_train, y_train)\n",
    "        final_X_array = zip(final_X_array, rus.sample_indices_)\n",
    "        final_y_array = zip(final_y_array, rus.sample_indices_)\n",
    "\n",
    "        final_X_array = sorted(final_X_array, key=lambda x : x[1])\n",
    "        final_y_array = sorted(final_y_array, key=lambda x : x[1])\n",
    "\n",
    "        final_X_array = [x[0] for x in final_X_array]\n",
    "        final_y_array = [x[0] for x in final_y_array]\n",
    "\n",
    "        np.savetxt(output/f\"under/x_train_subset_{idx+1}.csv\", final_X_array, delimiter=\",\", fmt=\"%5.2f\")\n",
    "        np.savetxt(output/f\"under/y_train_subset_{idx+1}.csv\", final_y_array, delimiter=\",\", fmt=\"%d\")\n",
    "\n",
    "        x_subset_file.close()\n",
    "        y_subset_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate for a single worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f\"./divided/train/{1}_workers/\"\n",
    "output = pathlib.Path(output_path)\n",
    "output.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "(output/\"raw\").mkdir(parents=True, exist_ok=True)\n",
    "x_file = open(output/f\"raw/x_train.csv\", \"wb\")\n",
    "y_file = open(output/f\"raw/y_train.csv\", \"wb\")\n",
    "\n",
    "rl_ids = [x for x in dataset.iterdir() if x.is_dir()]\n",
    "\n",
    "# Merging files into the number of workers\n",
    "for rl in rl_ids:\n",
    "    for file in [x for x in rl.iterdir() if x.is_file()]:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        time_sentitive_features = [feature for feature in df.columns if feature not in labels and feature not in identifiers]\n",
    "        np.savetxt(x_file, df[time_sentitive_features].values, delimiter=\",\", fmt=\"%5.2f\")\n",
    "        np.savetxt(y_file, df[[\"5-day-predict\"]].values, delimiter=\",\", fmt=\"%d\")\n",
    "        if df[time_sentitive_features].values.shape[1] != 620:\n",
    "            print(file)\n",
    "            print(list(df[time_sentitive_features].columns))\n",
    "\n",
    "x_file.close() \n",
    "y_file.close()\n",
    "\n",
    "#Undersampling\n",
    "(output/\"under\").mkdir(parents=True, exist_ok=True)\n",
    "X_train = np.loadtxt(output/\"raw/x_train.csv\", delimiter=\",\")\n",
    "y_train = np.loadtxt(output/\"raw/y_train.csv\", delimiter=\",\")\n",
    "\n",
    "final_X_array, final_y_array = rus.fit_resample(X_train, y_train)\n",
    "final_X_array = zip(final_X_array, rus.sample_indices_)\n",
    "final_y_array = zip(final_y_array, rus.sample_indices_)\n",
    "\n",
    "final_X_array = sorted(final_X_array, key=lambda x : x[1])\n",
    "final_y_array = sorted(final_y_array, key=lambda x : x[1])\n",
    "\n",
    "final_X_array = [x[0] for x in final_X_array]\n",
    "final_y_array = [x[0] for x in final_y_array]\n",
    "\n",
    "np.savetxt(output/\"under/x_train.csv\", final_X_array, delimiter=\",\", fmt=\"%5.2f\")\n",
    "np.savetxt(output/\"under/y_train.csv\", final_y_array, delimiter=\",\", fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersampling\n",
    "(output/\"under\").mkdir(parents=True, exist_ok=True)\n",
    "X_train = np.loadtxt(output/\"under/x_cv.csv\", delimiter=\",\")\n",
    "y_train = np.loadtxt(output/\"under/y_cv.csv\", delimiter=\",\")\n",
    "\n",
    "final_X_array, final_y_array = rus.fit_resample(X_train, y_train)\n",
    "final_X_array = zip(final_X_array, rus.sample_indices_)\n",
    "final_y_array = zip(final_y_array, rus.sample_indices_)\n",
    "\n",
    "final_X_array = sorted(final_X_array, key=lambda x : x[1])\n",
    "final_y_array = sorted(final_y_array, key=lambda x : x[1])\n",
    "\n",
    "final_X_array = [x[0] for x in final_X_array]\n",
    "final_y_array = [x[0] for x in final_y_array]\n",
    "\n",
    "np.savetxt(output/\"under/x_cv_under.csv\", final_X_array, delimiter=\",\", fmt=\"%5.2f\")\n",
    "np.savetxt(output/\"under/y_cv_under.csv\", final_y_array, delimiter=\",\", fmt=\"%d\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shallow_vs_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
